Artificial intelligence (AI)

What do we mean by "artificial intelligence"?
When we talk about AI today, we usually mean chatbots, which are generative AI. Examples of such AI tools are ChatGPT or Microsoft Copilot, which are used to generate text, images, or videos. The technology behind generative AI is deep learning. Large language models are based on deep learning algorithms, specifically a type pf neural networks called transformers (that is what the "T" in ChatGPT stands for). The large language model is fed with vasts amounts of text (usually scraped from the internet), and learn which words frequently appear together or follow each other. Based on these probabilities, the AI generates text that resembles human language.

When using a generative AI (prompting), the language model interprets what you have written and produces a response based on the probabilities it from the training texts. Because of this, you cannot expect the output from an AI to present truths, only probabilities.

Try it yourself! To investigate the limitations of AI, you can try asking it about something you already know a lot about. In the response, you will be able to notice how often AI generates incorrect/ambiguous/inadequate answers.

AI at Chalmers
Microsoft Copilot
As a Chalmers student you have access to Microsoft Copilot through an institutional license. That means that you get access to a more secure version of Copilot (previously named Bing Chat Enterprise) than if you were to use the free, open version.

Read more about how to activate and use Microsoft Copilot at Chalmers TopDesk.
It is up to the course responsible and examiner for each individual course to decide if and how AI is allowed to be used within the framework of the various examination tasks. Remember to ask at the beginning of each course! Read more here.

If you use AI tools, it is important that you refer correctly to these (see reference guide for APA and IEEE) and are transparent about how you have used them to produce your text/image.

When is it appropriate to use generative AI?

"Is it safe to use ChatGPT for your task?" by Aleksander Tiulkanov, licensed under CC BY

Bias
Because the output from generative AI is based on training data, it is crucial to know the properties of the texts included. If we imagine that AI has been trained on all the text available on the internet, it means that blog posts, opinion texts, fake news, tweets, and other dubious information are also included. This means that all forms of discrimination, sexism, racism, homophobia, etc. that exist on the open internet are also reflected in the AI’s generated responses.

It is also the most repeated opinions and perspectives that are generated by AI because the large language models are built on frequency, and the most dominant perspectives usually recur in the training data. Because of this, it is not possible to get nuanced images or analyses of social phenomena, as the most marginalized perspectives do not come to the fore.
Hallucinations
When we receive a response based on our prompt to a generative AI, the generated text may contain inaccuracies or completely fabricated facts. This is called AI hallucination. It is a result of how the underlying algorithms work, that is, through statistics and probabilities. An AI can hallucinate to varying degrees based on how it is built (for example, through hyperparameters such as top-p and temperature), but remember that there is always a risk of hallucinations - in all AI tools!

If you try to search for information through generative AI tools, you often encounter hallucinations in the form of fabricated references. Always check that the sources actually exist and read through the original text before referring to them in your own texts.

There are AI tools developed for information retrieval, such as Semantic Scholar, and these can be useful when you want to orient yourself in a new subject or want to expand your search beyond traditional scientific databases. However, information retrieval tools based on AI are not suitable for systematic literature reviews because the generated hit list is not replicable.
Intellectual property rights
The companies behind generative AI tools are usually not transparent about where they have taken the texts that have constituted the training data for the large language model. It is likely that some companies have scraped the internet for texts without the permission of the authors. Because the training data (probably) contains copyrighted material, the generated text/image is influenced by these, even though the copyright holder has not approved such use of their intellectual property rights.

A big question is also whether it is the “prompter” or the company behind the large language model (such as OpenAI for ChatGPT) that owns the generated response from a generative AI, that is, who owns the intellectual property rights to the output. It is also important to know that copyright laws may differ from country to country, which becomes problematic because many of the AI companies are based in the USA but can be used all over the world.

The issue of copyright with regard to AI is complex, and there are not enough legal cases to determine with certainty what type of use is acceptable in which situations yet. It is therefore very important to be cautious and consider how AI tools can be used ethically.



EXAMPLE: Jason M Allen and Théâtre D'opéra Spatial.
AI does not understand “Stochastic parrots”
Since generative AI produces text that is practically indistinguishable from something a human could write, it can give the impression that you are communicating with a conscious being. That’s not true. A generative AI is based on complex statistical models and is created with advanced deep learning techniques inspired by the neural networks in a human brain, but it cannot “understand” your prompt in the same way that a human can. The prompt is first broken down into so-called tokens, and then a response is generated based on the training data and the statistical models. How likely is it that this word follows this word…

There are many discussions about what can be considered intelligence and how intelligence is defined. There are different philosophical aspects to this, but as a user of AI tools, it is simply good to know the limitations of functionality. Generative AI can be described as stochastic parrots, which uses the metaphor of parrots that can mimic human speech but do not understand what they are saying.
Vary language model
Generative AI is based on large language models (which in turn are trained on different text collections and fed with different algorithms), which means that the functionality differs from tool to tool, even though both are generative AI. To learn as much as possible about what works for each tool and how to prompt most effectively, it is important not to get stuck using only one language model.

For example, the current version of ChatGPT is based on the GPT-4 language model. The GPT-4 language model is also used by Bing Chat Enterprise (which is the paid version of Bing Chat). Thus, a language model can be used for several different tools, even if the tools have different names and look different.

Another example is that many search services use the search engine developed by Semantic Scholars, including Research Rabbit.

Prompt engineering
The question/text that you send to an AI tool is called a prompt. To be able to generate helpful responses, one often needs to work out a good prompt by testing. The art/skill of prompting effectively is called prompt engineering.

Interacting with a generative AI generally has a very low threshold because it can interpret natural language, but if you want to develop your prompts, there are a number of best practice tips that you can follow.

The CLEAR Framework



Lo, L. S. (2023). The CLEAR path: A framework for enhancing information literacy through prompt engineering. The Journal of Academic Librarianship, 49(4). https://doi.org/10.1016/j.acalib.2023.102720

List of AI tools
The AI landscape is developing incredible fast! There are lots of websites, tools and plugins, and the amount increases each day. For most of these tools you need to create an account and pay for a subscription to access all the functionalities. Be critical when you create accounts and think about what control you have over the prompts and the generated responses.

Generative AI (text, image, video)

ChatGPT
Microsoft Copilot
Gemini
Information searching

Semantic Scholar
Elicit
Research Rabbit
SciSpace


Regulations for the use of AI tools in thesis work
Image 1 of 1
The examiner for your thesis determines the extent to which and how AI tools are allowed in your thesis work. It's important to note that this decision may vary among theses, even when they share the same examiner.

Consequently, you may have permission to employ AI tools for tasks such as generating text, code, and conducting data analysis, among other applications. However, this is contingent upon executing these tasks in a responsible and transparent manner, as outlined below.

You are required to assume full responsibility
You are required to assume full responsibility for your work and must be capable of justifying the choices you've made regarding its content. This includes engaging in discussions about and defending the role AI played in shaping your thesis, demonstrating a clear understanding of how it contributed.
When using AI tools in your thesis work, it's crucial to approach them responsibly, which means ethically, ensuring data integrity and academic honesty. This involves:

Being cautious of over-reliance on AI, which includes the risks of uncritically accepting AI-generated answers that can be biased or wrong. For example, do not uncritically accept a rewrite of your text, code, literature review, or analysis of your data.
Understanding the potential for plagiarism and copyright infringements. For example, GitHub Copilot has used copyright protected code when helping programmers to code, so always be vary of such problems.
That the use of AI tools must be clear and transparent. At a minimum, provide a description detailing how and to what extent AI tools have been utilized in your work. If you have used AI generated content in you thesis, this should be cited as other works.
Recognizing the need to secure sensitive or proprietary information. For example, you might have access to valuable information in the organization you are writing your thesis and sharing it with the AI tool might not be advisable.
Always consult with your supervisor
Always consult with your Chalmers’ supervisor or relevant industry/public sector collaborators before using AI tools if you have any uncertainties, particularly concerning data privacy and ethical issues. To date, Chalmers has licensing agreements in place with Bing Chat Enterprise, which include privacy arrangements.

Tags:
studies
education