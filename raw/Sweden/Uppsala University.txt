AI in Teaching and Learning
On 30 November 2022, ChatGPT was launched by the company OpenAI, making it openly and freely accessible. Neither this nor similar AI tools within so-called generative AI were new, but awareness of the technology, its potential, and its risks broke through significantly in higher education worldwide.

AI- week between Monday 28 October to Wednesday 6 November
AI in Teaching: Possibilities and Challenges

Under four headings
you will find information, advice, and other resources that support both institutions and individual teachers in managing the opportunities and challenges related to generative AI in teaching and examination. However, they do not address other types of AI.

Using Generative AI  for Teaching and Learning
The best way to understand the benefits and risks associated with the use of generative AI in your subject context is to test and experiment yourself. Since all teachers and students now have access to the Copilot tool, there are also opportunities to do this together with the students.

On these pages, six areas of use for generative AI are presented, which you can access via the links below. At the bottom of this page, there are some links where teachers have shared their ideas for teaching.

Share your experiences!
When so much is new and untested, there is more than ever to gain from learning from each other! Have you tried using AI in teaching? If so, please contact the unit for Academic Teaching and Learning and tell us how it went, whether it was a success or a disappointment! We compile and help spread teachers’ experiences.

Training Critical Use of AI
In certain educational programs, it is already necessary and uncontroversial to train students in using various AI tools that are, or are becoming, essential within relevant professional and research fields.

However, the widespread, rapidly increasing use of generative AI among students does not necessarily benefit their learning. Most students (and their teachers!) still lack a basic AI literacy that allows them to independently and competently reason about the pros and cons of working methods that include elements of generative AI in a given context.

By allowing students to work on tasks that involve the use of AI, teachers can help establish a critical, evaluative approach among students towards various AI tools and the material generated by them. This can foster discussions about the technology’s possibilities and limitations, thereby contributing to the development of students’ AI literacy.

Questions to Develop AI Literacy
Below are examples of questions that students may need to address.

Basic Knowledge
What is artificial intelligence (AI) and how does it differ from human intelligence?
What are the basic principles of how generative AI works?
Rules and Ethical Issues
What ethical considerations regarding AI are relevant in this context, especially concerning privacy and bias?
How can we ensure that AI systems are fair and non-discriminatory?
What are the institution’s guidelines and ethical considerations regarding the use of generative AI in coursework and examinations?
In what ways can I use generative AI to enhance my learning without compromising academic integrity?
Development of Good Practices
What are the main benefits of using AI in the current context? Are there clear drawbacks?
Why is it important and necessary not to use generative AI in a specific context (e.g., the current course or assignment)?
What skills and knowledge should I develop to effectively use generative AI in my studies?
How can I balance the use of generative AI with traditional study methods?
How can I critically evaluate and verify the information generated by AI tools?
How can I use generative AI to develop my own ideas and arguments instead of just relying on AI-generated content?
How can I ensure that the material I create with the help of generative AI does not violate copyright rules?
How should I reference material generated by AI?
Can generative AI be listed as a co-author of articles, etc.?
What are the potential risks of relying too much on generative AI in my academic work? In the short term? In the long term?
How can I contribute to the responsible use of generative AI?
Of course, no single course can cover all these aspects. However, within the framework of a program and/or a subject’s courses, from the introductory level up to master’s and doctoral education, it may be possible to coordinate course designs, assignments, and examinations so that all students, upon completing their studies, have had to work with all, or most of, the above points.

Examples
Here are links to articles, etc., that describe examples of how AI use has been integrated into teaching


Virignia Grande m.fl., Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics, 2024
Chrissi Nerantzi m.fl., 100+ Creative ideas to use AI in education, 2023
Incorporating Generative AI in Teaching and Learning: Faculty Examples Across Disciplines, Columbia University

Practising Prompting
The quality of the content generated by AI depends on the quality of the questions asked, i.e., the prompts that users input. Careless or insufficiently detailed prompts result in imprecise or even misleading answers.

So-called prompt engineering is therefore developing into an important skill. Much can be learned through trial and error, but for specific purposes within various subject areas, it pays to find strategies for effective prompting together with students. By comparing and analysing the outcomes of different prompts (or, more often, sequences of increasingly refined prompts), students become more adept at subject-specific working methods while gaining deeper knowledge and experience of the possibilities and limitations of using generative AI.

Prompting Tasks
Here are some suggestions on how prompt exercises can be structured. They can, of course, be varied in many ways and may require more or less detailed introductions, depending on prior knowledge and difficulty level.

Example of a Classroom Exercise
Students are divided into groups. Each group is given a task to be answered during the class session, preferably with some time pressure. The groups organise their work themselves. The use of generative AI is explicitly allowed (but does not have to be prescribed!). All prompts and generated answers must be saved. Each group then briefly presents their proposed solution to all other groups and how they arrived at it. In the concluding discussion, the solutions and the importance of the prompt work for their quality are compared.

Example of an Online Exercise
Students are given the same task, to be answered with the help of generative AI. Students work individually and are encouraged to save the entire conversation they have with Copilot. Students upload both their answer and the conversation in Studium, where the teacher has activated peer review. Each student reads and comments on the answers and prompt handling of 2-3 other students. In a follow-up discussion (synchronously in Zoom, or asynchronously in a discussion forum), the teacher leads a review where the results of different prompt strategies are compared.

More About Prompting
A very short introductiory video on writing good prompts in Copilot
Examples of prompts for educational purposes
Prompt Engineering Guide - a comprehensive overview
An interesting article, AI Prompt Engineering Isn’t the Future, which distinguishes between problem formulation and prompt engineering

Developing Practice Material
Generative AI can quickly produce texts or images that can be used to train students’ analytical skills. Naturally, it is more important and absolutely necessary for students to practice their critical abilities on authentic material, but there are several scenarios where AI-generated texts can be advantageously used.

Let students practice acting as reviewer (opponent)
It is well known that many new students are often unsure about the task of commenting on, or acting as formal reviewer of texts, written by their peers. Allowing students to practice on less successful texts from previous courses is not always a good idea, even if they are anonymised. Students may be uncomfortable with the idea that their own texts might be used in a similar way. Instead, selecting “VG-texts” (passed with distinction) can easily give students too narrow an idea of what a good essay should look like.

With the help of AI, teachers can easily generate several different texts on any subject, including references. Teachers can refine the texts in various ways, through follow-up instructions or by supplementing them themselves. Students - who are, of course, informed that the texts have been generated by AI - can then comment on and discuss the texts, online or in the classroom, and teachers can follow up on the students’ discussions. After a few rounds of initial exercises of this type, one should, of course, move on to discussing real texts.

In addition to training students in basic critical skills and academic discussions, it is also an excellent opportunity to discuss AI-related issues with students: academic integrity, independent work, etc.

Scenario exercises
Generative AI can quickly produce material that can be used in various types of scenario exercises. It can create a storyline for a role-play and even write dialogues for the different participants. It can formulate proposals for different cases if students are to work with case methodology.

Test it for yourself, and see how good the suggestions are for your specific subject area - the tools may not handle all areas equally well! Formulate your prompts carefully. Specify all important parameters that should be included, provide context and background, and specify the desired scope. Refine the result if necessary with additional prompts, or on your own. Always check the result to ensure it does not contain irrelevant or misleading details. If you request a script for a dialogue, remember that you can also specify the desired tone (humorous, angry, worried) and language level (formal spoken language, slang).

If you have old cases or role-plays that you want to develop, you can include them in the prompt and ask the tool to process them in the direction you want.

Matter for discussion
With the help of generative AI, you can easily produce material that can serve as a basis for discussions and various types of analytical exercises. For example, it is possible to generate, through well-chosen prompts, material that may contain errors, ambiguities, or weaknesses that students can practice quickly identifying, correcting, or improving. This could involve translating a text, checking programming code, formulating an application for a research project, providing an interpretation of a legal case, describing a historical event, carrying out calculations, analysing images or diagrams, and so on.

Such exercises may be best suited for beginner students who are still relatively inexperienced. After being trained to work on AI-generated material, they can more confidently tackle authentic material.

Diagnostic tests
Giving students the opportunity to take diagnostic tests, which are not graded, can have many benefits. It supports students’ learning, can prepare them for the actual examination, and can also give teachers an indication of the students’ knowledge level before the examination.

Generative AI can formulate multiple-choice or free-text questions in any subject in just a few minutes. Specify in the prompt which knowledge area and approximate level it concerns, how many questions are desired, the number of answer options, whether the correct answer (or for free-text questions, a suggested correct answer) should be provided, as well as other necessary parameters. As always, it is the teacher’s responsibility to check both the proposed questions and answers to ensure that no errors or ambiguities are included when creating the diagnostic tests and making them available to students.

Writing Assistance
Spell checkers and grammar checkers have been available for a long time and are hardly considered controversial. With generative AI, new possibilities have emerged. It is no longer just about correcting spelling or grammatical errors, but also about, for example, translation and suggestions for structure, not to mention that AI can produce content in response to user prompts. For some students, a few suggestions for introductory phrases or an overview of the answer’s structure can also serve as a way to overcome writer’s block.

What is prohibited and what is merely inappropriate?
But just because you can do something with AI does not mean you always should or are allowed to do it! Naturally, there are moments in language courses when there may be excellent reasons to deny students any use of AI tools. But the question is much more general than that: there is a significant risk that some students will gratefully accept linguistic assistance from AI without taking the time to consider why, for example, a particular introduction is preferable to another. Rarely or never trying to find a structure in the material themselves, but just accepting a suggestion from AI, also does not provide any analytical training. And letting AI generate content instead of working out the answer themselves can impair their understanding of the subject: the writing process itself is a way to process the material and develop and deepen their own reasoning, interpretations, and methods. And if the AI-generated content is part of an essay, a thesis, or another task which will be formally assessed, as part of the examination, it may be considered cheating.

Discuss and test AI assistance with students
The best approach is to address academic writing early in the course, especially if you know you have many new students, for example, in the first term of a program, so that students develop a better understanding of what possible restrictions that apply. Some points to address are:

The writing process as part of the learning process and not just a matter of external form
The importance of different contexts: in which contexts is it completely uncontroversial to use AI, when is it completely prohibited, and when is it questionable?
The importance of consistently considering and learning from AI’s suggestions
Any rules about when AI use must be indicated
Give students some topics or problems and then let them, during an intensive session in the classroom, or online, asynchronously, test all possible variants of AI support: generating complete answers, retrieving references, getting ideas and suggestions for structures and arguments, translating texts, and checking spelling, grammar, paragraphing, etc. Discuss the results and pros and cons together with the students.

Links about writing support
Guide to study strategies - self-study course in Studium, including academic writing

Language workshop - primarily a support for students, but also organizes courses for teachers at UU on working with students’ writing

AI as writing support in academic work -video (in Swedish) from Kristianstad University College

A. Bedington m.fl., Writing with generative AI and human-machine teaming: Insights and recommendations from faculty and students, Computers and Composition 74, 2024

AI as a Sounding Board
AI tools like ChatGPT, Gemini, Claude, etc., are all based on asking questions and receiving answers in a chat conversation – even though both questions and answers can contain more than just text, such as images or audio files. Students (and their teachers) thus have access to an tireless dialogue partner, around the clock.

Naturally, generative AI should not be seen as a replacement for discussions with classmates and teachers, but as an extension of the possibilities for dialogue. Here are several potential uses:

Support for Understanding
If a student struggles to understand a difficult passage in the course literature, they can ask AI to explain difficult concepts or to produce a simplified version of the text. This works best if the person asking takes the time to return to the original text, reflects on it again in light of the AI’s response, and perhaps even asks another question to ensure they have understood it correctly – and that the AI got it right.

Encouraging going in-depth
AI can quickly provide students with in-depth answers to questions about things they find particularly interesting during the course, and much more efficiently than a traditional internet search. A simply formulated question can give the student knowledge and insights that go beyond the narrowly course-related and stimulate a more open-ended, interest-driven curiosity.

Testing Ideas
It is possible to throw out more or less wild ideas for topics for papers or essays to get an initial indication of whether they seem reasonable and feasible, if they need to be developed, refined, or discarded. Just like with all other answers from AI, it is crucial to learn how to handle them correctly – one must assess their quality and not just accept them outright. One needs to ask follow-up questions, supplement with other types of information, and form a well-founded opinion on what can be done and why it might be worth doing.

It is worth noting that all the major tools are usually trained not to answer just anything. If one asks for arguments to make a typical conspiracy theory plausible, AI usually declines to answer this and instead warns against conspiracy theories.

Support in Studies
AI can also to some extent function as a mentor and study advisor. A doctoral student who is teaching for the first time can get constructive and helpful feedback on how they plan to conduct a teaching session, such as a lecture. A student can ask for good advice on how best to prepare for their first oral exam or ask for suggestions on different study paths for a future career. Students who are nervous about speaking in front of others at a seminar can get good advice on how to prepare.

The advice that AI can give is often noticeably good and kindly formulated, but can also sometimes be too general and not perfectly adapted to the situation. AI can very well play a positive and significant role, but it does not replace conversations with fellow students and teachers, nor the qualified, listening support offered by study advisors and Student Health Services.

Saving Teacher Time with AI
This page is from a teacher’s perspective, specifically addressing an aspect relevant to practically everyone working in higher education: to what extent can generative AI help free up valuable teacher time?

Below are some potential areas. The quality of the prompts you write and how you follow up the responses with new prompts are crucial, but different subjects and knowledge areas may also be better or worse served by different language models.

As always, when it comes to using generative AI, teachers need to consider the short- and long-term pros and cons in each individual case. Additionally, the material generated always needs to be reviewed and often adjusted.

Formulating Texts
Generative AI can formulate:

welcome letters for a course
suggestions for content for web pages
email responses (never upload sensitive or other information that can identify the recipient!)
suggestions for assessment criteria for assignments
course plans
instructions
exercises and discussion questions
exam questions in various subjects, with suggested answers
MCQ questions with different answer options
meeting minutes based on notes
text for slides in a presentation
Summarising Texts
Generative AI can summarise:

content from web pages (e.g., a current overview of a specific research area)
the content of documents
Note: Documents that are copyright-protected should not be uploaded without permission, and sensitive material should not be uploaded at all.

Producing Material
Generative AI can produce:

images for slides in a presentation
audio files
translations
subtitles for videos
suggestions for the structure of course modules
drafts for the outline of a lecture
program code
Long-term Possibilities
In the USA, generative AI is already used to assess answers in written exams and to provide feedback on student texts. In cases where systematic comparisons have been made with assessments and feedback from teachers, AI has often been as good or better, and it is likely that the systems will develop even more.

In a Swedish context, however, there are still ethical and legal questions that need to be answered before teachers can upload student work, including exams, for analysis by generative AI.

If it becomes formally allowed, and if teachers deem it otherwise appropriate, interesting possibilities for teaching open up. For example, it may suddenly become possible to provide qualified feedback on student work even in large courses with hundreds of students, freeing up teacher time for other efforts in the courses.

Further reading


J. Bliss, "AI Teaching Law in the Age of Generative AI", University of Denver Legal Studies Research Paper, January 2024, provides an interesting insight into American legal education, with both teacher and student perspectives from a field where generative AI is already widely used in professional practice.

From University of Oxford comes An introduction to the use of generative AI tools in teaching

From Harvard, The AI Pedagogy Project provides several concrete examples of assignments, where AI has been used, but also a general introduction to generative AI.

Generative AI and assessment
Teachers focus on assessing students’ learning, not on detecting potential cheating. However, there is a justified concern that written home assignments may no longer provide a good basis for assessment if students allow ready-made texts created by generative AI to replace their own intellectual effort. Unfortunately, it has also been shown that generative AI has been used in attempts to deceive during examinations.

All institutions need to review their examination practices, and these pages provide advice on how teachers can use AI to support examinations, how to prevent unauthorized use of AI, and how the examination format itself can be adapted. Additionally, there is a page with links related to examination issues.

All departments need to review their examination practices
and these pages provide advice on how teachers can use AI for assessment, how to prevent unauthorized use of generative AI, and how the examination format itself can be adapted. Additionally, there is a page with links related to examination issues.

Four overarching recommendations:
Focus on quality, not cheating! Avoid acting solely defensively! Invest in measures that improve the quality of examinations for all students, rather than primarily preventing cheating by a few!
Protect the academic learning environment! To be truly effective in the long term, all individual adjustments to the examination itself need to be part of a broader effort to preserve and strengthen learning environments characterized by curiosity-driven interest, critical thinking, and academic integrity.
Work collectively and collegially! This is not an area where all responsibility can be placed on individual teachers. Routines, support from management and administration, collegial discussion, and systematic exchange of experiences are needed.
Communicate clearly what applies to each course! Naturally, the majority of our students do not cheat - but many are deeply and genuinely unsure where the line is between permissible and impermissible use of generative AI in the courses they follow. Eliminate that uncertainty, but also explain why the line is drawn where it is!
 
Using AI in Examinations
As a teacher, you can naturally benefit from generative AI when conducting examinations. Below are some examples.

For all examples, as always with AI-generated material, you must check it, assess its reliability and suitability, and often adjust it before potentially using it.

Getting suggestions for exam questions/tasks
Formulating good exam questions, additional questions for retakes, and new questions that are not the same as last term’s can take a lot of time. Here, generative AI can help.

Write a prompt asking for a specified number of suggestions for exam questions or tasks. Specify as precisely as possible the area the questions pertain to, that it concerns university studies, and whether it involves beginner or more experienced students. Specify other parameters if necessary, such as excluding certain knowledge areas, or conversely, including them, if specific aids are allowed, the maximum number of characters or pages, etc. Naturally, you can also ask for example answers.

Remember that you don’t have to settle for the first suggestion that comes up; you can continue with new prompts in the same conversation and request adjustments, additions, etc., to the suggestions provided.

Getting suggestions for MCQ questions
Building a question bank of multiple-choice questions for use in, for example, online quizzes can be laborious. Here, generative AI can do the groundwork.

Write a prompt asking for a specified number of MCQ questions. Specify as precisely as possible the knowledge area the questions pertain to, that it concerns a university-level course, how many answer options should be available for each question, and whether you want single-choice, multiple-choice, or a mix of these. Also, ask for the correct answers to be marked, and specify any other parameters.

In less than ten minutes, you can have suggestions for 40-50 questions with the specified number of answer options, which you can then sift through and possibly adjust or correct.

Getting suggestions for rubrics
Based on the goals in a course syllabus, generative AI can provide suggestions for rubrics. The result may be insufficiently detailed and will undoubtedly need to be adjusted, adapted, and refined, but it can serve as a good starting point for developing an assessment matrix and save a lot of time.

Write a prompt asking for an assessment matrix with suggested criteria for all specified grade levels for each course goal in the attached syllabus. Paste the course goals from the syllabus and send the request. Possibly ask for further specifications of the suggested rubrics before you take over and process the result.

Uncertain ground 1: Getting suggestions for feedback on students’ answers
Good feedback, given reasonably close to the examination, can be a powerful support in students’ studies. At the same time, it takes time to provide qualified, written feedback, and with large student groups, it can mean that feedback on an exam comes with perhaps weeks of delay - when students are so busy with the next course and upcoming exam that they do not pay the feedback the attention it deserves.

At some American universities, generative AI is already used to provide feedback to students, and several studies have been conducted, also in European contexts, to compare the quality of feedback from AI with feedback from teachers. Most studies so far seem to show that experienced teachers still provide somewhat better (in some sense) feedback than AI, but that AI provides (in some sense) better feedback than less experienced teachers.

Write a prompt asking for constructive feedback on the attached text, which can be pasted in or attached as a file. Specify any parameters that detail how the feedback should be formatted: how long it should be, whether it should start by highlighting the best parts of the text (and explain why they are the best) and how the improvement suggestions should be formulated. Also, specify if AI should focus on certain things or completely ignore something, such as spelling errors.

Always review the result - you must be able to stand by everything sent to the student! Change, correct, remove, add, etc. Be transparent with the student and state that you have used AI to quickly provide feedback, but that you have reviewed and edited everything and that what they read is your opinion

Why is it uncertain ground?
It is likely that, for copyright reasons, you should not upload students’ texts without their permission to a digital tool. In the long run, this issue may be resolved, similar to plagiarism checks.

Three final points to consider:

Use UU’s Copilot if you upload students’ texts - not just any tools. And remove all identifying information from the text before uploading it.
Consider possible, unwanted side effects of using AI-generated feedback, even if it has been reviewed. For example, does the student-teacher relationship deteriorate in the long run if practically all feedback is AI-generated? And how will new teachers become skilled at providing feedback if they never have to do the work from scratch?
Also, consider what you do with the time you save! If you spend it on research or other tasks unrelated to the course, students may perceive it as a loss of teacher contact. But perhaps it is a time-saving measure that can allow for more contact with students, individually and/or in small groups? In that case, the combination of quick feedback and more meetings with teachers could mean a real improvement in teaching.

Uncertain Ground 2: Using Generative AI to Assess Exams
Just like with feedback, researchers and teachers have experimented with letting generative AI also “grade exams” and assess them. Here too, the results indicate that AI can quickly and competently go through large amounts of student responses, correct and assess them, although the results must, naturally, be checked.

Why is it Uncertain Ground?
Here too, the uncertainty about uploading students’ texts applies - permission from the students is likely required, and this issue may possibly be resolved.

When it comes to something as delicate as examination, which in Sweden is also an exercise of public authority, it is necessary to exercise great caution in using generative AI for assessment, even if the examiner reviews and approves the assessment. The EU AI Act considers examination to be a critical area where extra high demands are placed on users of generative AI, and for now, it is wise to refrain from letting AI grade exams.

Learn more!
Comparing the quality of human and ChatGPT feedback of students’ writing
Faculty members’ use of artificial intelligence to grade student papers: a case of implications

Communicate with students about AI
Preventive efforts are more long-term and should represent an integral part of the academic environment in which students spend their time at Uppsala University.

Use AI in teaching
Emphasise the examination as a form of teaching
Explain why the answering process is important, not just the answer
Vary the forms of assessment and take advantage of the students' progress
And of course: raise the issue of cheating!
Finally: continue to nurture the academic learning environment

Use AI in teaching
At this point, everyone knows so much about AI that it is a good idea to discuss its use in teaching. Familiarise yourself with one or several of the AI tools and test them out. Consider how they could be used as part of your teaching! For example, can an AI tool produce a simpler and clearer but fully correct version of a complicated text which could facilitate students' understanding (but be sure to let them read both – that is when it becomes truly interesting)? Give students tips about how and when to use AI as a positive aid in their studies, and explain when and why it is unnecessary, inappropriate or prohibited.

More advice and information will be shared in 2023 within the framework of the AI, teaching and assessment initiative, but some tips and ideas can be found via the links on the resources page.

Emphasise the examination as a form of teaching
From the University’s perspective, examination obviously serves as a control function that guarantees the quality of the programmes. Students’ studies are also governed to a large extent by the design of the examinations and by how exams and tests go, with concerns about finances etc. if they fall behind.

Although these aspects are unavoidable, it is still important for both teachers and students to talk more about – and to carry out – the exams as perhaps the most instructive part of the teaching, since students get the opportunity to see what they have learned and what they have not yet understood. The ability to access our memory (known as retrieval practice) and answer tricky questions is seen as vital nowadays for gaining more in-depth knowledge of a subject.

Examination therefore serves as a support mechanism for learning, and it is highly regrettable for it to be seen as a tool for control. Students who are tempted to cheat must realise how much knowledge and understanding of a subject is lost when they do so.

Explain why the answering process is important, not just the answer
This is closely related to the previous aspects. Students may focus on providing substantively correct answers and taking shortcuts to them – but the very process of working towards the answers and formulating them in a text of one’s own is in itself a central part of learning. The skill is as important as, or sometimes even more important than, the content of the answer.

Vary the forms of assessment and take advantage of the students' progress
Over the course of a semester or a programme, students should be able to use and demonstrate their acquired knowledge in several different ways – not all examination should be conducted using a single format, nor should there only be summative examinations at the end of a course or a module. Different types of continuous, formative assessment could also be a good solution. Moreover, if the course is structured in a way that assessment components consistently require the use of previously assessed knowledge and skills, it will be significantly more difficult to pass a course if you have previously cheated and thus do not have the required prior knowledge

And of course: raise the issue of cheating!
It is also a good idea to discuss academic integrity with the students at an early stage, as well as what is considered deceptive behaviour during assessments and what aids are prohibited etc. It is not necessarily crystal clear to them what the rules are or why. Ideally draw up a local page of resources for students and/or ensure they have access to the central resources available. Also produce standardised texts when talking about this so that not all teachers have to come up with their own every time. One example that could be used at the beginning of the semester:

“It is not permitted to use AI-generated texts (such as from ChatGPT) and to submit them as your own text. Ultimately, it is the teacher in charge of the course who decides which aids may be used, so feel free to ask them if you are unsure about what applies. However, unless explicitly stated otherwise, it is permitted to use AI-generated texts, so assume that it is not permitted.”

Finally: continue to nurture the academic learning environment
When students come to the University, they are no longer school pupils. They have come to an environment that builds upon a curious and critically probing approach to the world and to our attempts to understand and explain it. Their teachers may be learned, but they are not entirely learned, and could essentially be seen as their more experienced co-learners. In such an environment, researchers, teachers and students are naturally closely connected, and the ongoing development of each person’s own, independent thinking is not only at the core of the programmes offered, but of the whole University. This should be visible in all teaching and examination. In such an environment, having to retake an exam is of no concern, but cheating is unthinkable.

It may well be important for the students to hear words like these – but whether they remain words or actually characterise the learning environment and the relationship between teachers and students is borne out in the day-to-day work and approach at the departments.Hinder and detect prohibited use of AI
AI is constantly and rapidly developing, which makes it necessary to continuously monitor developments. Some advice and proposals can be found below, divided up into two categories:

Those that can be carried out fairly quickly and without complications, even by an individual teacher, and which revolve around how written homework assignments are formulated.
Those that require a major overhaul of assessment practice, and which may entail more comprehensive and resource-intensive measures.
Finally, a few lines are dedicated to the option of using AI tools to detect texts created by AI tools.

Three general recommendations are particularly important:
Focus on quality, not on cheating! Focus on measures that truly enhance the quality of examination for all students and whose primary focus is not simply on preventing cheating among a small minority.
Take a preventive approach too. The individual proposals below all need to be supplemented by broader, preventive efforts described on the previous page.
Work collaboratively and collegially. This is not an area in which all of the responsibility can be placed upon individual teachers. Procedures are required, along with support from management and the administration, collegial discussions and a systematic exchange of experiences.
1) Formulation of take-home assignments
The following two pieces of advice are relatively uncomplicated to implement and relate to how written take-home assignments are formulated.

Require even short texts to contain references.
Formulate questions to which the answer is to be either partially or fully based on or applied to local, specific contexts.
2) Review of examination practice
The following proposals, with the exception of the final one, are based on relatively extensive elements of feedback or follow-up. It goes without saying that this requires resources, and each subject area needs to produce its own assessment here of what is reasonable – but on a lot of courses it should be possible to shift more contact hours over to feedback.

Review which learning outcomes are assessed via take-home assignments.
Introduce more oral examination sessions.
Give feedback on various versions of the assignment.
Consider phased examination.
Use the University’s examination halls in new ways.
Note that in no case is it permitted to introduce new forms of examination on a course if they are not covered by the wording in the current syllabus, so this is a process that can take a relatively long time.

Proposals
Require even short texts to contain references
Start by reviewing the instructions for take-home exams, essays, etc. and require even short texts to state correct references, with correctly formulated source references of the literature used. This should be placed within the text and directly connected to the areas of relevance. Emphasise in the instructions that the references form part of the answer and will also be assessed and, where necessary, followed up.

Fortunately, the essence of this requirement is not about getting help in detecting possible cases of cheating. In actual fact, it can only be a positive thing for students to learn at an early stage to underpin their reasoning with careful references and to recognise the central role this part of the academic craft plays in crafting a scholarly discourse.

But in addition, the AI tools – as things stand, the picture is changing rapidly – often seem to have difficulty producing such references. The answers produced by ChatGPT (not to be confused with a search engine, as they are in fact a tool for generating comprehensible text based on instructions) are not always transparent, making it difficult and laborious to attempt to cheat by manually adding references subsequently to an AI-generated answer. Tools can invent entirely false references, but even in cases where the references really do lead to websites on the internet or articles that truly exist (Perplexity can produce such links), they are conspicuously imprecise and lack necessary page references, for example. For teachers, substandard or strange references can relatively easily offer a hint that a submitted take-home exam at least needs to be followed up more closely in an appropriate way. But even if everything looks good, teachers should get into the habit of taking a few random samples to check the references (and students must of course be informed that this will be done).

The instructions need not stop at merely requiring references:

Specify in the assignment instructions that the students must justify the selection of references they have included, for example
You could also ask the students to discuss the content of their references in detail.
Of course, this is not a solution to every single problem since not all written take-home assignments are suited to including references; other solutions may be needed. [Back]

Formulate questions to which the answer is to be either partially or fully based on, or applied to, local, specific contexts
Formulate assignments in which the students are to analyse, or in some other way relate to, activities carried out on that specific course based on course literature, etc. Alternatively, ask them to base or apply the reasoning in their answers on/to specific situations or circumstances that an AI tool could not easily know about. [Back]

Review which goals are assessed via take-home assignments and other potential forms of assessment
The selection of suitable forms of assessment is normally carried out based on the course’s learning outcomes, and for certain goals, take-home assignments are not the most suitable form of examination. For example, take-home assignments should have less focus on knowledge-based questions and more requirements relating to methodology and skills, such as the ability to select and justify what information and which source material is relevant to answering the assignment, as well as an independent, critical ability to analyse. Therefore, to be on the safe side, start by reviewing your examination practices. Perhaps there are take-home assignments that can very reasonably be replaced by supervised exams, or where examination can instead be conducted in connection with some other type of activity? [Back]

Oral examinations?
Another option that should be considered is oral examination. This may well seem overwhelming purely in terms of time, but it is often possible to assess several students at once – and after all, it also takes a lot of time to produce written exam questions and to mark piles of papers. The point at which it takes an equal amount of time to complete a series of oral exams does not have to be unrealistically far away – and sometimes an oral exam can do more justice to the students' knowledge. Note that relevant syllabi may need to be adjusted unless it is stated that oral examinations may be a possible form of examination.

If considering oral examinations, it is wise to first discuss at the faculty – but also subsequently at the department board and any other bodies that include student representatives – what guidelines should apply to such examinations so that they can be implemented fairly and securely. In the case of oral examination, it is particularly important to have clearly stated grading criteria that the students are aware of in advance and which can help teachers formulate appropriate questions. Above all, it is important to inform the students about the process and how the examination will be held at an early stage of the course, as oral examinations are perceived to be extremely stressful by many students. The Swedish Higher Education Authority’s document Fair Examination
 also proposes that oral examination can be documented to facilitate any grading reviews.

One option is to hold the oral examination as stage 2 of an assessment whose first stage is the submission of a written assignment. This would give the oral examination a tighter structure. Two such scenarios are described below.[Back]

Give feedback on various versions of the assignment
Essays in the degree project format are almost always produced as a series of versions that are discussed individually or in a group of students. When this type of process is used, whereby texts are produced gradually and their structure is discussed and adjusted continuously, it can be harder to rely on AI-generated texts. Of course, not all assignments are sufficiently extensive in scope to justify using this kind of process, but even for many short essay assignments, elements of discussion of drafts would make it harder to stand by a text that a student has not written themselves.

One option is to allow this type of discussion to be held partially or fully through some form of peer feedback, which in itself is an important element of learning. Especially early on in a programme, it can be important to provide students with some kind of support materials and examples that explain which components are important to enquire about.

Regardless of whether draft discussions are conducted with the teacher or fellow students, it is crucial that they are not carried out as, or perceived to be, a way of preventing cheating, but for them to form part of teaching and provide support for the students. If they make it less attractive to cheat in the process, that is merely a positive side-effect. [Back]

Consider phased examination
Not all take-home assignments consist of running text. Answers that largely consist of more formulaic text, such as programming code or mathematical or other formulae, cannot be underpinned by references in the same way. There are perhaps two paths to go down here: either move the examination to some kind of hall-based, invigilated exam (see further down on this page), or consistently invest resources in oral feedback, whereby the teacher meets the student – alone or in small groups – and has a discussion about the answers, with the student needing to orally justify and explain their choices. Naturally, in this case the students need to know in advance that the examination is not complete until after this second, oral stage: in this case, the feedback is given in connection with the examination itself. Check that the formulations concerning examination in the syllabus allow for this.

This would require resources in terms of contact hours, but it need not be a negative thing to redistribute contact hours from teaching before the exam to feedback on submitted work. It is an age-old problem that teachers have too little time for feedback and/or that feedback is not always sufficiently taken into consideration by students, despite it representing one of the most valuable elements of teaching. [Back]

Use the University’s examination halls in new ways
The University’s examination halls are often relatively empty. By opening up the examination halls on certain days for independent writing, we can take advantage of that opportunity to fully or partially check access to online aids. The tools are in place for allowing students to come at a time of their choosing to the examination hall during its opening hours and take exams in several different ways:

Using locked computers whereby the students log in as during an ordinary exam and have a limited timeframe to write answers using permitted resources they have brought from home (books, lecture notes and so forth) as well as approved, permitted online resources.
As above, but with the opportunity for students to return on multiple occasions to the examination hall and receive a new log-in for the same assignment with help from the invigilators. This would allow the assignment to be completed over the course of several days, yet still in a controlled environment.
Using open computers where the students have full access to the internet and the resources they bring from home, but with limited opportunities to collaborate with other students. The possibility of logging each student’s web history should be investigated, as an entirely open computer offers the chance to use chat rooms and social media.
Whenever an assignment is to be submitted, students would be required to submit them from the examination hall. This can be controlled, as a second log-in to the same assignment requires assistance from an invigilator, who gives the student access using an administrator password. It would thus be impossible for the student to start working on an assignment in the examination hall and complete it at a later date from another location using this method. However, it would be possible for students to return to the examination hall and receive a new log-in with help from the invigilators’ administrator password.

A written assignment can therefore be configured for students in several different ways:

As an assignment to be completed during a limited but flexibly structured timeframe. Settings can be configured in a way that gives students a limited time to respond from the time they begin the assignment, but they can choose when to start.
As an assignment that can be completed across multiple sittings. In this case, students can return to the examination hall another day or time to continue their work. They would not have an assigned computer or need to use a specific hall. For example, the assignment could be started at Bergsbrunnagatan and continued at Råbyvägen, but students would not be able to log in independently from home or from another computer room at the University.
To discuss possible options, contact tentamensamordning@uadm.uu.se [Tillbaka]

Can we produce new tools that detect AI-generated material?
Trials have already been carried out to see if AI tools can be used to check whether a text has been generated using AI. Several tools are available. For example, OpenAI has released its own AI Text Classifier. It is not perfect, however: it does not capture all AI-generated texts, it can also misclassify authentic texts as being written with help from AI, and only small changes in an AI-generated text are needed to pass the review.

These tools will undoubtedly be developed too, but so far there is no tool that allows teachers to carry out such checks systematically. Instead they need to carry out random checks, and in the end it still needs to be a question of the teacher's judgment, as is the case with the text-matching system. As technological developments are moving so rapidly, the most secure option is to not put our trust solely in technical solutions. Instead, modifying examination practice is a more sustainable and long-term solution that could also lead to other qualitative advantages for students’ learning. [Back]

More information about AI and assessment
 

Principles of good assessment and feedback from the British JISC (2022) does not specifically look at AI, but contains a lot of good information about assessment.

The great assessment rethink. How to measure learning and protect academic integrity in the age of ChatGPT, from Times Higher Education, is a resource with plenty of articles etc.

Articles:
Christiansen, M., Normark, L., & Swenne, C. L., "Hur AI-verktyget ChatGPT klarar en hemtentamen i palliativ vård", Högre utbildning 13(2), 2023, 56–62, https://doi.org/10.23865/hu.v13.5331

Zachari Swiecki, Hassan Khosravi, Guanliang Chen, et al., “Assessment in the age of artificial intelligence”, Computers and Education: Artificial Intelligence, 3, 2022, 100075,.

Michael R,King, chatGPT, “A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education”, Cel. Mol. Bioeng. 16, 2023, 1-2. Note: the text in the article was exclusively written by ChatGPT with the exception of the questions which were written by King

René F. Kizilcec, Elaine Huber, Elena C. Papanastasiou, Andrew Cram, Christos A. Makridis, Adele Smolansky, Sandris Zeivots, Corina Raduescu, "Perceived impact of generative AI on assessments: Comparing educator and student perspectives in Australia, Cyprus, and the United States", Computers and Education: Artificial Intelligence, Volume 7, 2024

Gustav Eliasson & Teo Gullström, Påverkan av generativ AI på lärande och kompetens inom högre utbildning, B.A. degree paper in Information Systems, Lund university (August, 2024)

Anders Eklöf & Lars-Erik Nilsson, "Om relationen rättssäker examination och artificiell intelligens – reflektion kring påträngande dilemman
", Högskolepedagogisk debatt 2024:1, 31-49, on AI and fair examination

Videos:
Two videos (in Swedish, no English sub-titles) have been produced by Mattias von Feilitzen at the University of Gothenburg entitled AI-genererade texter i högre utbildning. Implikationer för examination (AI-generated texts in higher education: implications for assessment): part 1 (16 minutes) and part 2 Duration: 11 minutes.

Websites with overviews, ideas, debates, etc.

Scientists Compared ChatGPT Writing Assessments to Human Assessments. Here’s What They Found - interesting reading (July, 2024)

My Students Are Submitting AI Papers. Here’s What I Do (June, 2024)

RIP assessment? - includes suggestions for action plan (June, 2024)

AI and assessment: Rethinking assessment strategies and supporting students in appropriate use of AI (May, 2024)

Rethinking Assessment for Generative AI: Beyond the Essay (May, 2024)

Assessment in a world of Generative AI: What might we lose? - a critical perspective (April, 2024)

Concerns mount as ChatGPT passes MBA exam given by Wharton professor (January. 2023)

A fundamentally positive voice: The potential of artificial intelligence in assessment feedback från Times Higher Education: Campus (August, 2022)

Recommendations for oral examinations from KTH in Stockholm, provides advice, and also a link to a recorded webinar on experiences of oral examination.

General information about Generative AI
Many still associate generative AI primarily with text from ChatGPT, but in reality, there are thousands of different, more or less specialized tools and services based on generative AI. What is generated does not necessarily have to be text; it can also be, for example, program code, images, video, or music.

Naturally, these tools were not primarily developed to cheat on homework. It is much more common for them to help owners of various websites, blogs, etc., to find material and generate new texts, making it easier to keep the sites updated.

How Does Generative AI Work?
Generative AI is just a part of the larger field of machine learning, which in turn is part of the overarching field of artificial intelligence. Tools based on generative AI create new content in the form of text, images, videos, etc.

How Do AI Tools Work?
The various tools generate content based on the instructions they receive from users, known as the prompt. The quality of the instructions is crucial for the quality of the result. For example, one can specify the scope of the answer, the style for a text or an image, specify that certain things should be excluded, or that certain perspectives should be compared, etc. Depending on the complexity, the answer is usually delivered within a few seconds (for shorter texts) or minutes (for images or other larger tasks). If you want to adjust, refine, or develop the result, you can give follow-up instructions.

Questions that involve and can be answered with more strictly rule-based, formulaic text – program code, mathematical formulas – have good chances of getting good answers, but translations between different languages are also constantly improving, and overall, the result is often – though not always! – impressive.

Probability, Not Truth!
The basis for all this is that the so-called language models that have been developed have been trained to recognize patterns in unimaginably large amounts of material – text, images, etc. When a tool using one of these language models receives a prompt, the question is interpreted based on patterns: a question containing these words in this sequence is likely to be answered with these words in this sequence (or, for example, with an image with this appearance; images can also be part of the training data). The generated answer thus constitutes an assumption based on statistical probability – not on any actual understanding of the content. Each feedback on the result in the form of new prompts refines these assumptions.

However, the process can sometimes deliver answers that contain completely false statements, constructed to fulfill what is requested in the instructions. For example, if you ask a question and request an answer that includes references to relevant sources, the result may be a list where the names of the journals, year, and volume number are correct, but the specified articles are missing when you check the references. They are entirely made up and cannot be found anywhere else on the internet, while other references may turn out to be correct.

More and more tools, however, also function as search engines, and do not only search material in a closed language model. The interpretation of the prompt also makes them look for information from the open internet to answer the questions and prompts they receive. But exactly how an answer came about can be difficult or impossible to know, and the quality of the actual references given is not guaranteed to be good. Therefore, the basic principle for users remains to always see the result they get as raw material, rather than an answer: it must be critically reviewed, evaluated, and often adjusted before it can be used (or sometimes discarded!).

Future Development
Generative AI continues to develop. Already now, enhanced AI support is available in programs such as Word, PowerPoint, Excel, and similar. There are also already tools for automatic subtitling of videos, as well as what is said in online meetings, in real-time, etc. As more material is fed into the models, and more people use the tools, write more detailed prompts, and provide feedback on the results, their answers get better and better.

At the same time, one can also see how the large, general tools, such as Microsoft’s Copilot or Google’s Gemini, are getting competition from smaller, but more specialized tools for specific purposes. Language models can receive special training (so-called fine-tuning) for more specific purposes, such as providing feedback on academic texts, grading exams, or writing code. Tools can also be limited so that no training data or user data leaves the organization.

More information
Explanation of basic terms (in Swedish)
AI-services at UU
Examples of other AI tools
An overview of the field of AI (in Swedish only)

Opportunities and Challenges
Generative AI is already being used by students, teachers, and researchers for various purposes. Here is a brief overview of the most commonly cited general advantages and disadvantages of using generative AI in higher education. Together, they can provide a quick entry into the discussion about the opportunities and risks of generative AI.

Advantages of Generative AI
Efficiency
Generative AI can perform certain types of time-consuming work much faster than humans: we can save a lot of time. Various tools offer the possibility to, for example:

Quickly summarise the content of long and/or many documents in a structured way
Assess students’ responses to written assignments based on set criteria and formulate feedback on them
Create formal meeting minutes from meeting notes
Draft text for standard emails to students
Find references that support the argumentation in a text
Individualisation of Teaching
Students’ activities on the digital platforms where much of their teaching takes place, where the material they produce is collected over time, and where their results are recorded can be analysed at an individual level through advanced Learning Analytics. Based on this, generative AI can automatically suggest relevant support resources and interventions and/or in-depth material. In this way, the university can offer increasingly better support for more individualised study paths, with both improved quality and throughput as the expected result.

Creativity
With tools like ChatGPT, one can have a conversation where ideas are thrown out, feedback is received, objections or clarifications are made, etc. AI can, for example:

Act as a sounding board to discuss possible solutions to a problem or to overcome writer’s block and get started with a text
Provide suggestions for the structure and content of a lecture, as well as create an accompanying PowerPoint presentation
Create images that illustrate your presentation
Provide text suggestions for a memo, report, or similar, complete with references
Text Processing
You can also use AI to process your own texts. Upload a text and:

Ask AI to perform a spelling and grammar check
Ask AI to simplify an advanced text so that it is better understood by someone with less prior knowledge of the subject
Ask AI to translate the text into English (or another language)
Necessary Adaptation
For various reasons, it may be considered inevitable to use AI. One could argue that:

For a curiosity-driven university, it may seem natural to test AI tools
It is no more dramatic than using a calculator - controversial at one time, but quickly normalised
Everyone is doing it - UU’s education should not fall behind
Various types of generative AI will become, or are already, commonplace in many of the professions students are aiming for
We must realise that we will never be able to convince students to spend a long time producing texts that they can generate in a few minutes with AI
Disadvantages of Generative AI
Unreliability
A fundamental objection concerns the quality of the answers generated by the various language models, which all suffer from weaknesses to varying degrees, such as:

Bias - the selection of training data is often skewed, and thus all generated answers risk, for example, disadvantaging certain language areas or reproducing various cultural stereotypes present in the training data. In the worst case, the answers can systematically contribute to reinforcing misconceptions and inaccuracies and confirming one-sided or distorted views.
Hallucinations - as it is called when AI tools simply produce completely fabricated facts and false statements. They are undoubtedly capable of sometimes lying very confidently and convincingly (without intending to lie, but solely to be able to provide an answer to a posed question).
Inconsistency - AI tools are accommodating and provide (with certain limitations) answers to exactly what you ask them. If you ask them to come up with an argument that disproves a previous answer, the tools will also assist with that. They cannot be trusted!
Generative AI thus places high demands on users’ source-critical competence!

Efficiency - Why and at What Cost?
Without a doubt, time can be saved, but:

The quality of the answers must always be assessed, and how will one learn a critical approach if one constantly skips the learning process that the evaluation and selection of sources for an argument entails, not to mention the intellectual processing that the formulation of one’s own arguments involves?
Even if experiments have shown that AI can provide feedback at the level of experienced teachers, how will new teachers ever become experienced assessors? Is it really likely that they will have time to review AI feedback? And how does it affect the students’ learning environment in the long run if teachers hand over more and more to AI?
Despite the fact that much is written about saving time, very little is said about what is done with the time saved. In the corporate or administrative world, one can naturally see simple advantages with increased productivity - but what does it mean in academia? Is the time spent on more research (which can also be made more efficient with AI)? Or is the time spent on teaching, perhaps to enable more meetings between teachers and students? Or are teachers laid off? And who decides what to do? The answers to these questions are more interesting than the statement that time can be saved.
How Creative Is It?
In many areas, important parts of the intellectual processing of a question often occur during the actual work of producing a well-formulated and well-structured text. The use of generative AI can lead to students missing out on an important practice moment.

Difficulties in Assessing Students’ Knowledge
A finished text of good quality has previously primarily been a sign that students have undergone a learning process with independent intellectual processing of material based on a problem statement. It is actually the implementation of that process that is examined in teaching. From a teacher’s perspective, texts and arguments that are increasingly generated by AI risk no longer providing a basis for fair assessment.

Refraining from Help
When it comes to simple language checks, it may rarely be necessary (except for certain tasks, e.g., in language subjects) - but students need to take the time to understand why, and if, linguistic or structural suggestions from AI are really better and even necessary, or if they prefer to ignore them. Will they have the time and energy to do that? Properly used, AI can be a powerful tool for mastering and developing one’s own language, but there is a risk that many students routinely accept all AI suggestions and in the process become linguistically poorer.

Fear of “Missing the Train”
has always been a poor argument for starting to use technology in educational contexts, as opposed to having good pedagogical reasons or doing it out of curiosity-driven interest.

Leaving calculations to a calculator is not the same as leaving the formulation of texts to an AI tool. Linguistic expressions are more fundamental to how we interpret, understand, and relate to the world, and the variation of different text types of different significance is enormous. Naturally, one does not always and for all types of texts need to attach equal importance to who formulated them, but the simple, sweeping analogy with the calculator is simply misleading.

That said, it is undoubtedly the case that all teachers need to know about AI tools and how they work, because students are already using them and it may need to have important consequences for how teaching and assessment are designed. And of course, education should prepare students for a professional life where AI plays an important role. But it is only from that analysis that a teaching staff can agree on what should apply to their courses and how it should be communicated to students. Anxiously starting to use generative AI primarily to avoid being outdated is not a good idea.

Ethical and Legal Issues
Finally, there are a few more problem areas that one may need to consider as a prospective user of generative AI. It is worth noting that these aspects are often raised by students as worrying factors.

What happens to academic integrity when students (but also teachers and researchers) can let AI tools search for sources, summarise them, suggest a disposition, and generate the article text? What still constitutes independent intellectual work? Where do we draw the line against cheating and fraudulent behaviour? And what transparency regarding AI use is needed to determine that?
There is also criticism, not least from the global south, of a colonial approach to data. The large language models that exist have primarily been developed by private, commercial companies in North America and Western Europe. However, they have been trained on data collected from around the world, often without any specific permission being obtained. The AI services are then sold and generate profit for the companies. Not everyone finds this reasonable.
An adjacent fairness aspect concerns how AI tools are “raised.” All major players equip their tools with various barriers to prevent them from generating content that is illegal or otherwise inappropriate. The systems, for example, refuse to answer questions about bomb-making, generate content that can constitute incitement to hatred, or images that show deeply offensive content. The necessary, demanding, and time-consuming work of reviewing material that should not be used to generate inappropriate responses is largely carried out by low-paid labour in the global south, while the users who benefit from it are still largely in the USA and Western Europe.
A fourth factor concerns sustainability aspects: generative AI consumes large amounts of energy compared to traditional web services. As language models grow and the number of users increases, more and more electricity is required to generate texts, images, videos, etc.
A final factor concerns intellectual property rights. In the USA, legal processes are already underway where copyright holders (visual artists, authors, etc.) seek retroactive compensation for their works being uploaded as training data to various language models. It is also a growing issue elsewhere and the subject of legislation at the EU level. The legal situation is still unclear - but there may be reason to refrain from uploading copyrighted material to AI tools without permission.

Regulations of AI - Laws and Guidelines
In a rapidly growing and challenging field like AI, it can be difficult to know what is allowed and appropriate, and what is considered prohibited or inappropriate. Many teachers and students have not had the time to think through and discuss the implications for education. No clear practice has yet been developed, and the applicability of older legislation or regulations may not be easy to determine.

The situation is naturally unsatisfactory for both teachers and students, who desire greater clarity.

In three areas, the development of AI has been particularly controversial in higher education: academic integrity; GDPR-related issues of personal privacy; and copyright issues.

Academic Integrity
Presenting work as one’s own, when it has actually been done by someone else, is a fundamental breach of academic integrity. In educational contexts, it is considered misleading during examinations. Here, various types of generative AI have contributed to the emergence of a grey area, where students often do not know where the line is between what is considered cheating and what is legitimate use of AI tools.

Different universities have reacted differently to the development. A few have temporarily banned their students from using generative AI altogether, which is likely unsustainable. More commonly, central and/or local guidelines are established to determine how AI may or may not be used in different situations. A common requirement may be transparency, i.e., that the extent of such use must always be declared clearly and openly. An international, European forum working on these and other issues is The European Network for Academic Integrity (ENAI).

Guidelines are undoubtedly desirable for the sake of clarity, but most importantly, the academic core values they protect should shape the students’ learning environment throughout their education.

Personal Privacy
The amounts of data handled by AI systems, which can also include potentially sensitive personal data, must be managed responsibly. The various tools naturally have their user terms that explain how personal data is handled, but there is also legislation that sets the framework for what is allowed. In the EU, the EU AI Act came into force in March 2024. Its requirements are primarily directed at the actors developing the tools, but also at the organizations making them available to their users, such as universities.

The EU AI Act completely prohibits certain uses of AI, especially when it infringes on personal privacy, and classifies other AI into different risk groups. The strictest regulations apply to a high-risk group, where specific requirements must be met. It can be noted that systems related to “Evaluating learning outcomes, including those used to steer the student’s learning process. Assessing the appropriate level of education for an individual. Monitoring and detecting prohibited student behaviour during tests” are classified in the high-risk group. For example, if one wants to develop advanced so-called learning analytics using AI, it is necessary to check how far it is possible to go.

The EU AI Act will undoubtedly have consequences for Swedish higher education, and hopefully, universities will soon gain greater clarity on what this may entail. In the meantime, users should follow existing regulations for handling personal data, and, for example, never upload students’ personal or contact information to various AI tools.

Copyright
A significant portion of the training data used to train language models has been copyrighted material - this applies to texts, images, and other media. Actors have generally not sought permission to upload this material, even though the language models would not have developed into the commercially successful systems they have become without access to it.

In the USA, this has already led to legal cases, where, among others, visual artists have sued companies for copyright infringement, while companies often claim so-called fair use. In the EU, a stricter approach is being established. The EU AI Act, among other things, stipulates requirements for greater transparency from the various platforms about what material has been used to train the models. The situation regarding possible compensation to copyright holders is still so unclear that it may be wise to be cautious about uploading protected material to AI tools.

Read More!

ENAI Recommendations on the ethical use of Artificial Intelligence in Education
The EU AI Act
Generative AI and Copyright Law
About copyright on AI-generated images
Proposal for the design of local guidelines for the use of generative AI for students at UU

Läs mer!
ENAI Recommendations on the ethical use of Artificial Intelligence in Education
The EU AI Act
Generative AI and Copyright Law
About copyright on AI-generated images
Suggestions for the design of local guidelines for the use of generative AI by students at UU

Support and Professional Development
Not only students but also university staff need to develop a basic AI literacy. Some of this can be done individually, but other parts should be done together to achieve a necessary consensus among colleagues on how AI issues should be handled.

On these pages,
resources and materials offered by the unit for Academic Teaching and Learning are gathered for both individual teachers and departments.

Within the university, there are several other central and local units and nodes that can also provide support in developing teachers’ and students’ AI literacy. A list of links is available at the bottom of this page.

What Needs to Be Done?
The suggestions are aimed at both individual teachers and those with management responsibilities - heads of departments, directors of studies, programme coordinators, etc.

Since the launch of ChatGPT 3 in November 2022, most subjects and departments have begun to find reasonable approaches for their own teaching. Depending on how far along they are in this process, the proposed measures and activities suggested here are more or less relevant

For Teachers
Hopefully, as a teacher, and perhaps also as a course coordinator, you are part of a context where you can continuously discuss opportunities and challenges with colleagues, share your experiences with them, and learn from theirs. This is especially important when technological development is as rapid as it is with generative AI, while our practices and understanding of the consequences AI can or needs to have for our teaching do not develop as quickly.

Below are some suggestions for what you may need to do to manage the situation and develop both your and your students’ AI literacy. If there are several teachers on the same course or module, it is beneficial to do as much of this together as possible.

Step 1: Identify opportunities and risks in the courses you teach
To assess what generative AI can mean for your teaching, you need to know a bit about how generative AI works and the general opportunities and risks that exist. Then, from your subject perspective, the formal course objectives, and your pedagogical ideas, you can more clearly see what needs to be changed for generative AI to play a positive role in students’ learning, and to prevent students from using generative AI in other contexts.

You can, for example:

Read briefly about how generative AI works
Review a list of pros and cons of AI in education
Read about how AI can be used in teaching and assessment
Deepen your knowledge with online courses, etc.
And of course, test some tools yourself, primarily in Copilot, which teachers and students at UU have access to
While you are finding a reasonable approach, it is good to early on try to formulate how you will justify the use or non-use of generative AI - students will surely ask about it.

This does not have to be a simple process - but talk to your colleagues and look out for seminars and workshops that can be helpful.

Step 2: Revise or create new course material
You will likely need to work on three things:

Review how you assess the course! If you need to adjust the form of examinations to ensure you still have a good basis for your assessment, try to find a form that not only is defensive but, if possible, improves the assessment! You can, for example, read more about preventing cheating and making cheating more difficult. Remember that changes in the form of assessment may require changes in the course syllabus - and it can take time to get through!
Think through other parts of the course, which are not assessed by formal examinations, and what role - if any - you want generative AI to play there. Often, many students will surely use some AI tool, and when examination is not involved, it does not have to be a problem or something that always needs to be reported. However, as a teacher, you may want to highlight how AI is used, and in the instructions for certain tasks explicitly assign students to use AI, and then discuss interesting questions about this during the course. Some suggestions for such questions can be found on the page about practicing critical AI use.
Formulate a text that as clearly and precisely as possible states what is allowed and not allowed use of generative AI in the course and its various parts. If there are central guidelines, you can refer to them, but each course always needs a document that applies specifically to your course and is addressed to your students! In this document, you can also include your justifications for any limitations you specify. You can start from these examples of local regulations for courses.
Step 3: Communicate with students about AI use
The document you have prepared should be published in Studium, preferably at the same time as the rest of the course page is published. Show where it is and go through it orally at the introduction to the course or module, and refer back to it during the course. Make it clear that the regulations are those that apply to your course, even if other courses the students have taken have made different decisions.

Set aside time to discuss the content of the document (and then you should have your justifications ready) and be prepared to be influenced by students’ good arguments! If there are central guidelines that students need to know, you should show them as well. Emphasize to students that it is their responsibility to always contact the course coordinator directly if they are at all unsure about how the regulations should be interpreted!

Make room to problematize and deepen AI use during the course. Through your way of formulating, handling, and discussing generative AI with students, you contribute to shaping their AI literacy.

And above all: do not be overwhelmed by AI so that its opportunities and risks overshadow the reason why both you and the students are there! Together with you, students delve into knowledge areas, theories, methodological questions, and problems where generative AI is a tool - sometimes necessary, sometimes just peripheral or unnecessary - among others. It does not replace the development of the critically grounded, independent understanding of the world that one seeks at a university - and which is not only expressed in front of a screen, if anyone thought so.



 For departments and programs
The rapid development of generative AI is such that it is not reasonable to leave it to each individual teacher to explore the field and draw conclusions for teaching on their own. The short-term challenges regarding examination practices require collegial discussions, as do the long-term challenges regarding how generative AI might affect students’ learning in the future.

Complete consensus on all issues is neither possible nor desirable, but within each department, subject, or program, it is necessary to discuss what should apply to everyone and what needs to be decided at the course and teacher level. Naturally, it is then important to communicate clearly to both teachers and students what applies, but also to be able to justify what applies.

Step 1: Determine the Starting Point
Knowledge about generative AI, and interest and engagement in AI-related issues, varies not only between scientific fields and subjects but also within each subject. A first step is therefore to gather the teaching staff and appropriately inventory the range of hopes, fears, questions, and wishes within the teaching staff. One of the goals of this review is to identify the continuing education needs within the teaching staff so that everyone can develop a basic AI literacy.

Doing this together, in small group discussions, and not primarily through, for example, a survey, is a good idea, partly because more unexpected things can come up in informal conversations with colleagues, in addition to what the groups are asked to discuss. Once you have gathered what has emerged, you can, if necessary, follow up with a survey to get even better data for the continued work from a management perspective - but start rather with the collegial conversation!

This first step should result in a concrete proposal for continued development, with purposes, a timeline, and responsible contact persons indicated, shared with the teaching staff.

Step 2: Measures in Three Areas
As university teachers, we usually and fortunately enjoy a great deal of trust from the employer to independently design the teaching. However, during the ongoing AI development, there are three areas where initiatives from the management level play a crucial role.

Review of Examination Practices
Each course and program needs to review and, if necessary, develop its examination practices so that they still provide teachers with a good basis for assessing how much students have learned. Here, directors of studies and others need to take multiple responsibilities:

They need to ensure that examination practices in all programs have considered the AI issue.
Program managers need to ensure that changes made at the course level do not lead to distortions that make student progression more difficult.
They may need to initiate a discussion in the teaching staff about whether examination practices need to be improved. Replacing all home assignments with in-class exams is a simple way to handle risks with generative AI but can lead to significant quality losses. How could the quality of the examination be improved without compromising security?
Communication with Students about What Applies
From the students’ side, uncertainty about what applies regarding the use of generative AI is a growing concern. Exactly what limitations apply often must, of necessity, be decided within the framework of each course. From the management level, in consultation with the teaching staff and student representatives, you can:

Discuss the need for common, local guidelines for the use of generative AI, and formulate such guidelines if necessary.
Determine how students should be informed about what applies, both at the department or program level and at the course level.
Continuing Education and Reflection
To develop a basic, general AI literacy, there is a lot that teachers (including those working at the management level!) can do on their own (but encourage teachers to carry out such activities together!).

But it may also be appropriate to gather the entire or parts of the staff for more exploratory workshops. Three important areas for such workshops can be:

Practical skills, where teachers test, try and compare prompts, review results, etc.
How to maintain and strengthen the academic learning environment - curious exploration and critical examination, with research and teaching close to each other - within the department/subject/program.
How to maintain and strengthen academic integrity, i.e., “compliance with ethical and professional principles, standards, practices, and a consistent system of values, that serves as guidance for making decisions and taking actions in education, research, and scholarship” (definition from ENAI).
Step 3: Structures for Long-Term Work
The most important contribution that the management level can make to promote long-term and deepened development is to ensure that there is a well-functioning, fixed structure that gives teachers the opportunity to regularly share their experiences from teaching (and it does not have to be solely about generative AI!). Hearing colleagues talk about, and discussing concrete examples from teaching, with reflections on the implementation, whether it turned out more or less successful, can be among the most effective ways to develop a deeper understanding of the possibilities and limitations of generative AI within one’s own subject. And why not let students hold a teaching day and show examples of how they use generative AI?

Some departments already have such a vibrant culture of sharing, but others may need to strengthen it. Of central importance can also be how the experiences that emerge are managed so that they are included in an accessible knowledge bank and can be passed on to new teachers.

Support for Implementation
If you would like advice or practical support in implementing the measures described above, you are welcome to contact the unit for Academic Teaching and Learning. We have conducted workshops on generative AI for teachers from all of the university's three domains and led discussions and exercises tailored to the different needs and conditions that different departments, subjects, and programs may have. Please contact us for a consultation!

Consultative Support
The Unit for Academic Teaching and Learning (enheten för universitetspedagogik, in the following, UP) offers various forms of consultative support, including for generative AI in teaching. The starting point for all consultations is that all activities are planned in consultation with the respective department, subject, or program, so that the content is tailored to the specific needs of the teaching staff.

Examples of Activities
Staff from UP can:

Give presentations on various aspects of generative AI from a pedagogical perspective
Act as discussion partners and sounding boards in the development of local action plans
Lead and facilitate workshops on a teaching day about generative AI where a teaching staff works on concrete tasks and discusses solutions to various problems
Provide support to teaching groups developing new or revising existing courses or course components
Design and lead tailored training sessions where participants who complete all elements receive certificates that can be added to a pedagogical merit portfolio

Learn from each other
Sharing and discussing experiences with other teachers provides ideas for your own teaching and is also an excellent way to learn more about the possibilities and limitations of generative AI. Often, this happens informally, in conversations with colleagues over coffee, but given the ongoing rapid development of both technology and the practices of students and teachers, there may be reason to create more structured forms for exchanging experiences.

At the Department Level
Within a department, a subject, or a program, heads of departments, directors of studies, etc., can take formal responsibility for managing experiences. The simplest way to organize the exchange of experiences is within the framework of regularly recurring teacher days and subject conferences. Feel free to vary the formats (perhaps poster sessions and not just presentations) and the content (by sometimes focusing on specific issues rather than a mixed smorgasbord of experiences). An important aspect to consider is how to document and follow up on what emerges.

Collegial Networks
For ongoing discussions, collegial networks work better. For a network to function, it is wise to find a realistic level of ambition, a form that matches it, and to distribute responsibility within the network.

In a network with many engaged members and where a lot is happening, it often works best to work asynchronously, online; if there are fewer participants and long intervals between sharing, it probably works better to plan a few real-time meetings, preferably in person. Someone needs to take formal responsibility for the network (to manage the online environment or to schedule network meetings), but if the activity level is too low, with more readers than contributors, it is advisable to agree on rotating responsibility among the network members to contribute something. When a network is kept alive solely by the efforts of the responsible person, it is usually time to shut it down and find another form.

Choose How You Communicate with colleagues
If you want to work online and share materials, discuss with each other, and collect links to other resources, you can create collaboration spaces online in SharePoint, which all employees have access to (see the link at the bottom of the page).

As usual with tools that offer many possibilities, it also requires more from the users. Make sure you choose tools that really suit your network and its level of ambition! Sometimes a traditional mailing list may very well suffice for a network. It is often better to start simple and let it grow in line with the network’s needs than to create an advanced collaboration space from the beginning that largely remains deserted and underused.

Across Subject and University Boundaries
There is currently no network where teachers from all of Uppsala University can share and discuss experiences of using AI in teaching. However, the seminars and workshops organized by the unit for Academic Teaching and Learning can serve as a possible arena for exchanging experiences. Every other year, a higher education pedagogical conference is also organized where you can submit contributions.

Share your experiences!
Good ideas deserve to be spread even outside your local environments - and sometimes you learn as much or more from setbacks! Contact the unit for Academic Teaching and Learning if you want other teachers at UU to learn about how you and your students have used generative AI! We help spread your examples through courses, seminars, and other activities.

Material for use
Uppsala University offers hundreds of courses each term, across a wide range of subjects. What responsible teachers consider to be permissible or impermissible use of generative AI can vary greatly between different courses, and even between different components of a course, so overarching guidelines often need to be supplemented by local regulations.

Here are suggestions
for what may need to be included in local regulations, as well as examples of texts, which can be downloaded and adjusted according to individual needs.

Please note
that a proposal for central guidelines on the use of generative AI at Uppsala University is currently under review (until mid-September 2024). Depending on if and when the guidelines are adopted, the templates on this page may be updated.

What should be included?
What points typically need to be included in a document addressed to students in a specific course?

A reference to any overarching guidelines (above the course level) that apply to all courses
An explanation of why additional, course-specific regulations are necessary
A clear description of the contexts in which the regulations apply
The regulations themselves, clearly formulated with any exceptions clearly stated
A description of the consequences of unauthorized AI use
A reminder to students that if they are unsure about what applies, they are responsible for contacting their teachers for clarification
Comments
You can, of course, link to pages with overarching guidelines, but it is easier for students if they are copied and displayed together with the local regulations, so that students have all the information on the same page.
As a teacher, you should be able to explain why the regulations are necessary! The arguments can naturally relate to course-specific learning objectives, where you can refer to the syllabus and explain why certain uses of generative AI are deemed to negatively impact students' learning. They can also concern more long-term program goals, but naturally also general academic principles that students need to learn to observe.
You may want to emphasize that it is part of the formal mandate and pedagogical responsibility you have as a course coordinator to make these types of assessments.
How detailed the justifications need to be can vary: sometimes quite short justifications may suffice, which can instead be elaborated on orally at the beginning of the course.
In practice, it is in connection with assessed tasks that the regulations become relevant, but this still needs to be clearly expressed. It may sometimes be desirable for students to refrain from using generative AI even for non-assessed tasks, but it is rarely possible to control. Therefore, it does not fit into a document of this type but is best handled within the framework of teaching, as a recommendation, an exhortation, or simply as part of the normal working method during the course.
The regulations should preferably be as specific as possible:
- Does it apply to all tasks? In some courses, it may vary between different tasks, and then a line should be inserted to carefully read the instructions for each individual task.
- Does it apply to all AI tools, or only some?
- Does it apply to all purposes, or only some? Perhaps AI can be used for ideas, but not to generate any text/code/image to be submitted?
- Is transparency about any use required? How detailed should students specify it?
- Something that often creates uncertainty concerns the use of tools that utilize AI for spelling and language checks. Always specify what applies, and if and how any use should be reported
Explain that unauthorized use of AI in connection with examinations is considered misleading in examinations, and explain what that means and can lead to (preferably link to the university page).
Specify whether questions should always be directed to the course coordinator, or primarily to the teacher who examines the task. Repeat that the regulations are course-specific, and that students should never assume that the same applies as in other courses they have taken.
How should it be formulated?
The text should not be too long, but short and concise. Sometimes you may want to provide longer explanations, e.g., regarding justifications: these should perhaps rather be placed immediately adjacent to the main text. You can also consider whether some introductory sentences are needed about the role of generative AI in the subject area and in the professional life awaiting the students.

Even though the text is about the limits of what is allowed, it is good if its design and tone make it clear to students that the limitations are not primarily a control issue, but exist for their sake, i.e., to ensure that teaching and examination truly serve their purpose and support, stimulate, and deepen students' learning.

How should it be communicated?
In a clear, prominent place in Studium! In both written course information before the course starts, as well as orally, preferably at the first meeting of the course, the information should also be repeated and the place in Studium shown.

Provide an opportunity to ask questions about the regulations, and show openness to discussing them with students – it is a discussion needed to develop both teachers' and students' AI literacy.

Update the regulations
Evaluate how well your local regulations (and the central ones!) work in practice. Discuss with students and colleagues, and be prepared to change things that do not work and are counterproductive or unrealistic. Given the rapid development of both technology and practice, it is not unlikely that you will need to review and update the regulations before each term starts.

Materials for institutions, disciplines, programs
Here is a template for use at the departmental, discipline, or program levelWord, 19 kB.. Please feel free to download it, but use it as a starting point and not as a finished document. Make sure to create a document that truly reflects your own needs and requirements!**

Here is also an example of guidelines (in English) for teachers and students in the master's programs at the Faculty of MedicinePdf, 234 kB.
 (the document is shared with permission from MPK).

Materials for courses
Here is a template for use at the course levelWord, 19 kB.. Please feel free to download it, but use it as a starting point and not as a finished document. Make sure to create a document that truly reflects your own needs and requirements!

Proposed guidelines on AI in teaching and assessment
2024-06-18

Hand at computer keyboard with symbols and text “AI”.
Proposed guidelines and guidance on AI in teaching and assessment are under internal consultation at the University. Photo: Getty images.

Proposed guidelines and guidance on AI in teaching and assessment are out for internal consultation at Uppsala University until 20 September 2024.

The guidelines are intended to give students and teachers the opportunity to explore the possibilities of AI in higher education without compromising academic integrity. Guidelines on the use of AI in teaching and assessment have been requested by various parties at Uppsala University.

The proposals have been developed by a working group appointed by the Vice-Chancellor, including representatives for teachers, students, faculty offices, the Division for Quality Enhancement, the Legal Affairs Division, the Student Affairs and Academic Registry Division, University IT Services and the University Library.

Guidelines + guidance
The proposals are divided into two parts: guidelines and guidance. They have been divided up in this way to tackle the rapid developments currently taking place in the field of AI.

The guidelines are intended to provide a concise overview of the applicable rules and are aimed at both teachers and students. They will be approved by the Vice-Chancellor.

The guidance expans on the reasoning with examples and is intended to help people better understand the guidelines. The guidance is primarily aimed at teachers and is intended to be edited and improved on an ongoing basis.

Standing working group
The guidelines may also need to be updated frequently, given the rapid developments in the area. The working group behind the proposed guidelines therefore proposes that a standing working group be established to monitor this area and, if necessary, quickly propose updates to the guidelines.

Anders Berndt

Proposed guidelines on the use of generative AI in teaching and assessment
he proposed guidelines comprise one page of A4; the following is just the bullet-point list from the proposal. There will also be a guidance document comprising roughly six A4 pages. The internal consultation including the proposal has registration no. UFV 2023/2129. 

1. When students’ use of generative AI in connection with teaching or assessment needs to be limited or accounted for, this must be clearly stated in written information provided by the course coordinator. This restriction must be justified based on the learning outcomes and the nature of the task.

2. Students planning to use generative AI in their studies are responsible for keeping themselves informed of both central and, where applicable, local guidelines on the relevant programme/course.

3. If students are expected to use generative AI in connection with teaching, course coordinators must be able to provide them with tools at no cost to the student.

4. The responsibility for how AI-generated material is managed rests with the user.

5. Sensitive data must not be transferred to generative AI systems.

6. Copyrighted and similar material should not be uploaded to generative AI systems without the authorisation of the rights holder. Please note that this also applies to texts written by students and doctoral students, for example.