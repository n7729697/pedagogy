AI for student learning and support
Some ideas of how AI can support student in learning and preparing for assessment have been outlined here. Mollick and Mollick (2023) provide further guidance in terms of the roles that AI can take.  

Mentor - AI provides feedback to the learner 
Tutor – AI provides direct instruction that will be personalised  
Coach – AI works with the students to increase metacognition, for example reflect on a recent group learning experience 
Teammate – AI acts as a team mate providing alternative functions and suggesting ways to help teams function better 
Student – students ‘teach’ AI about a topic and evaluate the output correcting any misconceptions 
Simulator – AI builds different role playing scenarios where students can focus on specific concepts or problems to solve  
All of the roles AI can assume are explained in detail in Mollick and Mollick’s (2023) paper with sample prompts to give the AI appropriate persona and instructions and practical advice.  

Mollick, Ethan R. and Mollick, Lilach, Assigning AI: Seven Approaches for Students, with Prompts (September 23, 2023). Available at SSRN: https://ssrn.com/abstract=4475995 or http://dx.doi.org/10.2139/ssrn.4475995 

Developing students’ AI literacy
What is AI literacy? 

AI literacy has been defined as: 

“A set of competencies that enables individuals to critically evaluate I technologies; communicate and collaborate effectively with AI; and use AI as a tool online, at home and in the workplace” AI Unplugged, Georgia Tech University
According to Newcastle University this involves: 

“recognise AI and when you are interacting with it in existing and new platforms 
develop a basic knowledge of how different types of AI work and the human role in AI 
critically analyse what AI can do and distinguish between types of AI 
develop an awareness of what AI might be able to do in the future 
identify the strengths, weaknesses and limitations of AI 
develop a critical awareness of how computers learn from data and the impact this has 
describe the key ethical issues surrounding AI and its use in education including for academic integrity 
critically evaluate information generated by AI and make informed decisions about its use in your work 
communicate successfully with AI including creating effective prompts.” 
Source: https://www.ncl.ac.uk/academic-skills-kit/information-and-digital-skills/ai-literacy/ 

AI literacy is an emerging concept that is constantly evolving into frameworks that translate what it specifically entails. Some emerging frameworks are: 

Kara Kennedy, researcher 
King’s PAIR activity 
How to help students develop AI literacy?
Developing students’ literacy should focus on several areas: 

Helping students understand how AI software works 
Letting students learn how to use the tool, i.e. gaining practical experience of how to use it 
Critically evaluate source and outputs – this includes understanding the limitations of AI in relation to for example searching, or ‘hallucinating’ sources 
Prompt engineering – students’ ability to use AI effectively relies on their ability to create suitable prompts and their understanding how different wording might alter the output. Some guidance on that was produced by ChatGPT and can be found here.  
Ethical use of AI to produce work – including departmental rules around AI use and appropriate acknowledgment of AI input. More information on that can be found on the Library webpages.  
An example of a session that focused on helping students develop AI literacy can be found in the Reflective Essay case study. You can find the briefing slides in the downloadable documents section of this case study. 

AI presents opportunities to streamline and assist with certain aspects of teaching practice. Some examples from the literature and the wider sector include: 

Generating additional examples to illustrate points for teaching
Providing multiple explanations of the same idea/ concept
Analysing main themes from student feedback from such classroom assessment techniques as the Muddiest point or One minute paper.
The examples above are based on Mollick and Mollick (2023). More guidance on the theoretical rationale for each of those uses as well as practical tips on how to work with LLM to generate those can be found in the paper. A short video with some ideas produced by the two authors can also be found in this video. 
Further ideas include:

Developing questions to low stake tests – some guidance on this can be found in this case study.
Refining marking rubrics – an example of this is discussed in the reflective essays case study. The case study website contains a downloadable resources box where you can see what prompts were used to generate and refine rubrics (under prompt Engineering for rubrics file)
Helping to generate drafts of lesson plans
Helping refine feedback – here it is important to ensure that the assessment is done by you and AI simply helps you refine the feedback. An important consideration needs to be given whether this should be disclosed to the students.
Generating automated feedback – an example of this is the Lambda feedback project where students’ answers are analysed and feedback automatically generated based on students’ past mistakes.
Assessment overview

It is highly unlikely that the students would use
AI software to fully generate the assignment.
This is because the essay focuses on personal
understandings of the problems and understanding
of their own ideas, situations in the context of the
knowledge that they encounter. The use of AI on the
programme is encouraged as a tool to help them
learn effectively. This is exemplified by the following
suggested uses:
• Using AI to help students think about language
constructions. However, they shouldn’t just cut
and paste the answers generated by AI as this
would be classed as plagiarism. Paraphrasing
is allowed in the sense of them doing the
paraphrasing of the content generated by AI.
Asking the system to paraphrase and then
simply cutting and pasting the generated answer
is not allowed and if detected would count as
plagiarism and incur penalty.
• Using AI to help students develop aims and
objectives for their essays
• Using AI to get a better understanding of the
module material
It is important to clearly outline to the students
what is permitted and what is not permitted when it
comes to AI. The College encourages staff to create
opportunities where students’ AI literacy can be
developed. College’s approach to the use of AI for
assessment is outlined in “AI tools in teaching and
assessment” document.

AI is very good at solving knowledge based questions
testing facts or direct relationships as well as these
questions that do not require a lot of diagrams, figures
or graphs as it can’t read those well at this point. This
means that it can successfully solve about 30% of first
year problems and 20% of second year problems. This
score is relatively low because the questions were
already designed more in the style of open book exams.
Questions that are testing advanced knowledge are safe
as currently they are too complex for AI to solve. They can
be solved by breaking them down and explaining them
to the AI, which is what a more expert user would be able
to do, however if a student is able to break the problems
down, they would also be able to solve them without
the help of AI so the need to use the software becomes
redundant.
AI software can be used to help generate exam or more
so pop quizzes questions. Those can be multiple choice
questions or Fill-In-The-Blank questions. Questions can
be generated based on learning outcomes or objectives.
The command could look like this: “Generate a multiple-
choice question with exactly 4 options based on the
learning objective: ‘Introduction to Python Programming’.
Output in CSV format of the following structure: question,
correct option (one of the four options), option1, option2,
option3, option4. This query would be executed as
many times as needed (e.g., 30), gradually coming up
with numerous potential questions. The teacher who requested these would then sift through the results and select the ones that were useful (ie. were relevant,
meaningful, and made sense), thus creating a pool to pull questions from while randomly generating pop-
quizzes for students.
One thing to note that the questions that tend to be suggested by some software (for example ChatGPT) are
more aligned with the US based curriculum.

Automated answers design
When using automatically marked exams one of the important things to
consider is the amount of differentiation within an allowed answer and
ensuring that all allowed variations are entered into the system. This is
not something that you need to do in the same way on a paper test but is
extremely important in a computer test. Therefore ensuring that you take
into account and input every correct answer that the computer would mark
as incorrect is a big task.
To ensure that the questions and answers work, we test each question on
GTAs who are asked to do those questions as students. This allows us to
see if any types of mistakes come up with certain answers hence allows for
better quality assurance of the exam.
Rationale for the software used
The software used to manage the electronic midterm exams is WISEflow.
There were two main reasons why this particular software was found most
suitable: flexibility in the type of question that can be used and real time
progress monitoring (which is unique for this type of software).
Previously, the Easter test and the Christmas tests that were also electronic
were conducted on Blackboard. The only possible question type was
mainly MCQs. One big benefit of WISEflow it allows a lot of question types.
This means that 90% of typical exam questions in the department can be
translated to an electronic format. The software also allows us to customise
questions for students through reshuffling the order in which they appear
as well as amending the values that students work with, which helps to
stop collusion.
Another big feature is the ability to monitor student progress in real
time. This means that throughout the duration of the exam you can see
how much time students are taking on each question, what percentage
finished the test at what point in time. The software does not monitor any
other activity (i.e. what is appearing on students’ screens or doesn’t use
their camera to record what they are doing physically) but having the data
around how far into the test students are allows us to support students who
might be having technical issues or helps to identify any questions that the
cohort is generally struggling with. We use that information in the following
years to adjust the assessments.

STEP 1: Reflect and examine 

Drawing on your experience and knowledge of the programme reflect to what extent AI poses a challenge or an opportunity for your assessment. Consider past student behaviours, feedback and characteristics of the assessment strategy on the module/ programme and the future of the industry. 

Reflect and examine
Collapse all
To what extent do you believe that the question/ the brief could be easily answered by AI?
Assessments that test understanding via reproducing facts with minimal application and reflection are more easily performed by AI. It is important to consider whether testing recall and understanding is important, or whether this can be tested through demonstrating higher level skills, such as application (in order to apply students will have to understand). 

To what extent do you expect academic misconduct with AI be an issue on your module? Has plagiarism been an issue on your course?
Examine students’ past behaviours. Cohorts and their approaches to learning and assessment will differ, however, if plagiarism has been an issue before it might also be the case now that AI tools are so easily available. 

To what extent do you think students feel overloaded with assessment on the module? Do students feel over-assessed on your course?
Look into feedback from past cohorts. Do students report on being overwhelmed with the amount of work they have to do? High assessment load can lead to pressure that might force students to adopt coping strategies to deal with the workload. This means being strategic and undesirable use of AI to produce assignments could be a part of that strategy.  

Are a lot of deadlines bunched together clashing with other assessments on the programme?
A lot of assessments happening at the same time might further contribute to students feeling overwhelmed with high workload and therefore force students to use AI strategically in inappropriate ways. 

Do you see AI playing an important role in students’ future professional lives?
Guiding academic integrity and quality of assessment is important but considering AI use in terms of its place within the industry is also important when deciding on how to approach AI use. If you predict AI will be an important part of students’ working lives it is important to teach them how to make best use of the tools they will be working with in the future. 

STEP 2: Assess your assessment

If you suspect that AI might cause real issues on your programme it is useful to stress test your assessment. The Business School developed the stress test to assess to what extent assessments quality across different Business courses would be compromised by AI.  

Use your choice of AI software and input your assessment question. Examine the output by considering the following questions: 

Did the AI provide information that is factually correct and up-to-date? 
Was the AI's response coherent, logically developed and free from unnecessary repetition? 
Did the AI address the question effectively? (i.e. did it directly address the central question or topic? 
Did the AI follow the instructions given in the task? For example, if the task asked for a response in a particular format (e.g., an essay or a report), used a specific methodology or addressed a certain number of points, compliance would measure how well the AI adhered to these requirements. 
Was the AI able to provide accurate and appropriate references when required in the response? 
Was the AI tool straightforward and efficient to use in completing the assessment?. 
Now reflect on the following: 

How likely is it that the output would receive a good grade? (work with your marking criteria to determine that) 
How easy would it be to recognize the output as produced by AI? 

STEP 3: Make a decision on how to approach AI on your module

There are a couple of approaches that you can take to dealing with AI in assessment. This will depend on whether you perceive AI to be a threat to the integrity of your assessment strategy or an opportunity.

Use the interactive AI decision tree below (or download the PDF version of the AI decision tree) to help you think through some questions that you might have to ask yourself and arrive at potential outcomes. 

AI in education
